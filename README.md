```
Íµ¨ÏÑ±:

# TIA(Today I Analyzed) - My Project
## Description
Í∞ÄÏÑ§ Í≤ÄÏ†ïÏùÑ ÌÜµÌïú Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÎøêÎßå ÏïÑÎãàÎùº Ïõπ Ïä§ÌÅ¨ÎûòÌïëÏù¥ÎÇò APIÎ•º ÏÇ¨Ïö©Ìïú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë, Î®∏Ïã†Îü¨Îãù ÏòàÏ∏° Î™®Îç∏ÎßÅ Îì± 
Îã§ÏñëÌïú ÌîÑÎ°úÏ†ùÌä∏Î•º ÌÜµÌï¥ Îç∞Ïù¥ÌÑ∞ ÌôúÏö© Î∞è Î∂ÑÏÑù Ïä§ÌÇ¨ÏùÑ ÏóÖÎç∞Ïù¥Ìä∏ÌïòÍ≥† ÏûàÏäµÎãàÎã§.
- Ìè¥ÎçîÎ™ÖÏù¥ 00_Î°ú ÏãúÏûëÌï©ÎãàÎã§.
- (Ï∞∏Í≥†)8Î≤à ÌîÑÎ°úÏ†ùÌä∏Î∂ÄÌÑ∞ Î≥∏ Î†àÌè¨ÏßÄÌÜ†Î¶¨Î•º ÏΩîÎìú Ï†ÄÏû•ÏÜåÎ°ú ÌôúÏö©Ìï©ÎãàÎã§. 
Î∂ÑÏÑù ÎÇ¥Ïö©Í≥º ÏûêÏÑ∏Ìïú ÏÑ§Î™ÖÏùÄ Î∏îÎ°úÍ∑∏Ïóê Í∏∞Î°ùÌïòÍ≥† ÏûàÏúºÎãà ÌïòÎã®ÏóêÏÑú Í∞Å ÌîÑÎ°úÏ†ùÌä∏ ÎßÅÌÅ¨Î•º Ï∞∏Í≥†Î∞îÎûçÎãàÎã§.

# TIA(Today I Analyzed) - Kaggle Study
## Description
Ï¢ãÏùÄ Ïª§ÎÑêÏù¥ ÏûàÎã§Î©¥ Îî∞Îùº ÏûëÏÑ±ÌïòÎ©¥ÏÑú Í≥µÎ∂ÄÌï¥Î≥¥Í≥†, ÏßÅÏ†ë Î∂ÑÏÑùÎèÑ ÌïòÍ≥† ÏûàÏäµÎãàÎã§. 
Îî∞Îùº ÏûëÏÑ±Ìïú ÏΩîÎìúÏùò Í≤ΩÏö∞ Readme Î™©Ï∞® ÌÉÄÏù¥ÌãÄÏóê +ÌëúÏãúÎ•º Ìï¥ÎíÄÏäµÎãàÎã§.
- ÌÉÄÏù¥ÌãÄ Î≤àÌò∏Îäî Îç∞Ïù¥ÌÑ∞Ïóê Îî∞Îùº Îß§Í≤ºÏäµÎãàÎã§. 
- Î≤àÌò∏Í∞Ä Í∞ôÎã§Î©¥ ÎèôÏùºÌïú Îç∞Ïù¥ÌÑ∞Î•º ÏÇ¨Ïö©Ìïú ÏΩîÎìúÏûÖÎãàÎã§.
- Î≤àÌò∏Í∞Ä ÏóÜÎã§Î©¥(ex. 20) ÏßÅÏ†ë Î∂ÑÏÑùÌïú Ïª§ÎÑêÏù¥ ÏóÜÎäî Í≤ΩÏö∞ÏûÖÎãàÎã§.
```


# TIA(Today I Analyzed) - My Project
## Description
Í∞ÄÏÑ§ Í≤ÄÏ†ïÏùÑ ÌÜµÌïú Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÎøêÎßå ÏïÑÎãàÎùº Ïõπ Ïä§ÌÅ¨ÎûòÌïëÏù¥ÎÇò APIÎ•º ÏÇ¨Ïö©Ìïú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë, Î®∏Ïã†Îü¨Îãù ÏòàÏ∏° Î™®Îç∏ÎßÅ Îì± 
Îã§ÏñëÌïú ÌîÑÎ°úÏ†ùÌä∏Î•º ÌÜµÌï¥ Îç∞Ïù¥ÌÑ∞ ÌôúÏö© Î∞è Î∂ÑÏÑù Ïä§ÌÇ¨ÏùÑ ÏóÖÎç∞Ïù¥Ìä∏ÌïòÍ≥† ÏûàÏäµÎãàÎã§.

**[1. ÎÑ∑ÌîåÎ¶≠Ïä§Ïùò ÏΩòÌÖêÏ∏† Î≥¥Ïú† ÌòÑÌô©Í≥º ÏàòÍ∏â Ï†ÑÎûµ Î∂ÑÏÑù](https://github.com/sw-song/TIA/blob/main/00_01_netflix_trend_analysis/analysis_strategy_in_netflix.ipynb)**
```
Step 1. Í∞ÄÏÑ§ ÏÑ§Ï†ï
Step 2. Í∏∞Î≥∏ Ï†ÑÏ≤òÎ¶¨
     2-1. Î∂àÌïÑÏöîÌïú Ïª¨Îüº Ï†úÍ±∞
     2-2. Î∂àÌïÑÏöîÌïú Ìñâ Ï†úÍ±∞
     2-3. Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ Î≥ÄÌôò
     2-4. ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò
     2-5. Îç∞Ïù¥ÌÑ∞ Íµ¨Í∞Ñ(ÏãúÍ∞Ñ) Î∂ÑÌï†
Step 3. Í∞ÄÏÑ§ Í≤ÄÏ†ï
     3-1. ÌäπÏ†ï ÏΩòÌÖêÏ∏† Ïú†ÌòïÏóê ÎåÄÌïú ÏßëÏ§ë ÏàòÍ∏â Ïó¨Î∂Ä Î∂ÑÏÑù
     3-2. ÌäπÏ†ï Íµ≠Í∞ÄÎ•º Í≤®ÎÉ•Ìïú ÏΩòÌÖêÏ∏† ÌòÑÌô© Î∂ÑÏÑù
     3-3. ÏΩòÌÖêÏ∏† ÏàòÍ∏â ÎåÄÏÉÅ Ïó∞ÎèÑ Î∂ÑÏÑù
     3-4. ÎÑ∑ÌîåÎ¶≠Ïä§Ïùò Ï£ºÏöî ÏÜåÎπÑÏûê ÌÉÄÍ≤ü(Ïó∞Î†πÎåÄ) Î∂ÑÏÑù
     3-5. ÏΩòÌÖêÏ∏† ÌèâÍ∑† Ïû¨ÏÉù ÏãúÍ∞Ñ Î∂ÑÏÑù
     3-5. ÎÑ∑ÌîåÎ¶≠Ïä§ÏóêÏÑú Ï£ºÎ°ú ÏàòÍ∏âÌïòÎäî ÏΩòÌÖêÏ∏† Ïû•Î•¥ Î∂ÑÏÑù
Step 4. Ï¢ÖÌï© Í≤∞Î°†
```

**[2. Ïª§Î®∏Ïä§ Í≥†Í∞ùÏùò Ïó∞Í∞Ñ ÏßÄÏ∂úÏï° Î∂ÑÏÑùÏùÑ ÌÜµÌïú Îß§Ï∂ú Í∞úÏÑ† ÏãúÎÆ¨Î†àÏù¥ÏÖò](https://github.com/sw-song/TIA/blob/main/00_02_ecommerce/ecommerce.ipynb)**
```
Step 1. Í∞ÄÏÑ§ ÏÑ§Ï†ï
Step 2. Í∞ÄÏÑ§ Í≤ÄÏ†ï
     2-1. ÌèâÍ∑† ÏÑ∏ÏÖò Ï†ëÏÜç ÏãúÍ∞ÑÏóê Îî∞Î•∏ Ïó∞Í∞Ñ ÏßÄÏ∂úÏï° ÌôïÏù∏
     2-2. Í∞ÄÏûÖ Í∏∞Í∞ÑÏóê Îî∞Î•∏ Ïó∞Í∞Ñ ÏßÄÏ∂úÏï° ÌôïÏù∏
     2-3. Ïï±, Ïõπ ÏÇ¨Ïö© ÏãúÍ∞Ñ ÎπÑÍµê
     2-4. Ïï± ÏÇ¨Ïö© ÏãúÍ∞ÑÏóê Îî∞Î•∏ Ïó∞Í∞Ñ ÏßÄÏ∂úÏï° ÌôïÏù∏
     2-5 Ïõπ ÏÇ¨Ïö© ÏãúÍ∞ÑÏóê Îî∞Î•∏ Ïó∞Í∞Ñ ÏßÄÏ∂úÏï° ÌôïÏù∏
     2-6. Í∞ÄÏûÖ Í∏∞Í∞ÑÏóê Îî∞Î•∏ Íµ¨Îß§ Í≤ΩÎ°úÏóê ÎåÄÌïú ÏÑ†Ìò∏ÎèÑ Ï∞®Ïù¥ Î∂ÑÏÑù
     2-7. Í∞ÄÏûÖ Í∏∞Í∞ÑÏóê Îî∞Î•∏ Íµ¨Îß§ Í≤ΩÎ°ú Î≥Ñ Ïó∞Í∞Ñ ÏßÄÏ∂úÏï° ÌôïÏù∏
Step 3. Î∂ÑÏÑù Í≤∞Í≥º
Step 4. Îß§Ï∂ú Í∞úÏÑ† ÏãúÎÆ¨Î†àÏù¥ÏÖò
```

**[3. Ï¶ùÍ∂åÏÇ¨(ÌÇ§ÏõÄÏ¶ùÍ∂å) APIÎ•º ÌôúÏö©Ìïú ÎπÑ Ïã§ÏãúÍ∞Ñ(Batch) Ï£ºÍ∞Ä Ï†ïÎ≥¥ ÏàòÏßë](https://github.com/sw-song/TIA/blob/main/00_03_pykiwoom/pykiwoom_test.ipynb)**
```
Step 1. Í∞úÏöî
     1-1. Ï£ºÏãù Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞©Ïãù ÎπÑÍµê
     1-2. pykiwoom
Step 2. Î°úÍ∑∏Ïù∏ Î∞è Ï†ëÏÜç ÏÉÅÌÉú Ï°∞Ìöå
     2-1. ÌôòÍ≤Ω ÏÑ§Ï†ï
     2-2. ÏûêÎèô Î°úÍ∑∏Ïù∏ Ïã§Ìñâ
Step 3. Í∏∞Î≥∏ Ï¢ÖÎ™© Ï†ïÎ≥¥ ÏàòÏßë
     3-1. Ï¢ÖÎ™© ÏΩîÎìú ÏàòÏßë
     3-2. Í∞úÎ≥Ñ Ï¢ÖÎ™© Ï†ïÎ≥¥ ÏàòÏßë
Step 4. Ï£ºÍ∞Ä Ï†ïÎ≥¥ ÏàòÏßë
     4-1. Í∞úÎ≥Ñ Ï£ºÏãù Ï†ïÎ≥¥ ÏàòÏßë
     4-2. Í∞úÎ≥Ñ Ï£ºÏãù ÏùºÎ¥â Ï∞®Ìä∏ Ï°∞Ìöå
```

**[4. Í∞ÄÏÑ§ Í≤ÄÏ†ïÏùÑ ÌÜµÌïú Ïπ¥Ïπ¥Ïò§ Ï£ºÏãù Îß§Îß§ Î∞±ÌÖåÏä§ÌåÖ](https://github.com/sw-song/TIA/blob/main/00_04_backtesting/kakao_backtesting.ipynb)**
```
Step 1. Ïπ¥Ïπ¥Ïò§ Ï£ºÏãùÏùÑ 1999ÎÖÑ 11Ïõî 11ÏùºÏóê 100ÎßåÏõê Ïπò ÏÉÄÎã§Î©¥ Ïò§Îäò ÏñºÎßàÏùºÍπå?
     1-1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Ìò∏Ï∂ú Î∞è Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏
     1-2. Í∞ÄÏÑ§ Í≤ÄÏ†ï
Step 2. Ïπ¥Ïπ¥Ïò§ Ï£ºÍ∞ÄÎäî Ïñ∏Ï†úÎÇò ÏÉÅÏäπÏû•Ïù¥ÏóàÏùÑÍπå?
     2-1. Í∞ÄÏÑ§ Í≤ÄÏ†ï(ÏùºÎ¥â Ï∞®Ìä∏)
     2-2. Í∞ÄÏÑ§ Í≤ÄÏ†ï(365Ïùº Ïù¥ÎèôÌèâÍ∑†ÏÑ†)
Step 3. ÏàòÎ©¥Ï†ú Î®πÍ≥† ÏûêÎäî Í≤ÉÎ≥¥Îã§ Îçî ÎÇòÏùÄ ÏàòÏùµÏùÑ ÎÇº Ïàò ÏûàÏùÑÍπå?
     3-1. Ïù¥Îèô ÌèâÍ∑† Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
     3-2. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨(change Ïª¨Îüº)
     3-3. Î∞±ÌÖåÏä§ÌåÖ Ï†ÑÎûµ ÏÑ§Í≥Ñ
     3-4. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨(Îß§Îß§ Íµ¨Í∞Ñ Ï≤òÎ¶¨ - overs Ïª¨Îüº)
     3-5. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨(Îß§Îß§ Ïã†Ìò∏ ÌëúÍ∏∞ - signal Ïª¨Îüº)
     3-6. Í∞ÄÏÑ§ Í≤ÄÏ†ï(Îß§ÏûÖÏï° ÌòÑÏû¨Í∞Ä ÎπÑÍµê)
```

**[5. (1) Î¨∏Ï†ú ÏÉÅÌô© Í∞ÄÏ†ï Î∞è Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ | Í¥ëÍ≥† ÌîÑÎ°úÎ™®ÏÖò Ìö®Ïú® Ï¶ùÏßÑÏùÑ ÏúÑÌïú Ïª§Î®∏Ïä§ Í≥†Í∞ù ÏÑ∏Î∂ÑÌôî](https://github.com/sw-song/TIA/blob/main/00_05_customer_segmentation/customer_personality_analysis.ipynb)**
```
Step 1. Î¨∏Ï†ú ÏÉÅÌô© Í∞ÄÏ†ï Î∞è Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ 
     1-1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Ìò∏Ï∂ú Î∞è Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏ 
     1-2. ÏùºÎ∂Ä Ïª¨Îüº Ï†úÍ±∞ 
     1-3. Ïª¨ÎüºÎ™Ö, Îç∞Ïù¥ÌÑ∞ÌÉÄÏûÖ ÌòïÏãù ÌÜµÏùº 
     1-4. ÌòÑÏû¨ ÎÇ†Ïßú Í∞ÄÏ†ï 
     1-5. Ïù¥ÏÉÅÏπò Ï≤òÎ¶¨
```

**[5. (2) Í≥†Í∞ù Íµ∞Ïßë Î∂ÑÏÑù | Í¥ëÍ≥† ÌîÑÎ°úÎ™®ÏÖò Ìö®Ïú® Ï¶ùÏßÑÏùÑ ÏúÑÌïú Ïª§Î®∏Ïä§ Í≥†Í∞ù ÏÑ∏Î∂ÑÌôî](https://github.com/sw-song/TIA/blob/main/00_05_customer_segmentation/customer_personality_analysis.ipynb)**
```
Step 2. Í≥†Í∞ù Í∑∏Î£π ÏÑ∏Î∂ÑÌôî
     2-1. ÎÇòÏù¥Ïóê Îî∞Îùº Î∂ÑÎ•òÌïòÍ∏∞
     2-2. ÏµúÍ∑º Íµ¨Îß§ÏùºÏûêÏóê Îî∞Îùº Î∂ÑÎ•òÌïòÍ∏∞
     2-3. Í∞ÄÏûÖ Í∏∞Í∞ÑÏóê Îî∞Îùº Î∂ÑÎ•òÌïòÍ∏∞
     2-4. Ïª¥ÌîåÎ†àÏù∏ Ïó¨Î∂ÄÏóê Îî∞Îùº Î∂ÑÎ•òÌïòÍ∏∞
     2-5. Ïò®/Ïò§ÌîÑÎùºÏù∏ ÏÑ†Ìò∏ÎèÑÏóê Îî∞Îùº Î∂ÑÎ•òÌïòÍ∏∞
     2-6. ÌîÑÎ°úÎ™®ÏÖò ÎèôÏùò Ïó¨Î∂ÄÏóê Îî∞Îùº Î∂ÑÎ•òÌïòÍ∏∞
     2-7. Î®∏Ïã†Îü¨ÎãùÏúºÎ°ú Î∂ÑÎ•òÌïòÍ∏∞
```

**[6. Í≥ºÍ±∞ Ï£ºÍ∞Ä Îç∞Ïù¥ÌÑ∞Î°ú ÎØ∏Îûò Ï£ºÍ∞ÄÎ•º ÏòàÏ∏°Ìï† Ïàò ÏûàÏùÑÍπå? | ÌååÏù¥Ïç¨ Ìå®ÌÑ¥ Í≤ÄÏÉâÍ∏∞ Íµ¨ÌòÑ](https://github.com/sw-song/TIA/blob/main/00_06_pattern_search/pattern_search.ipynb)**
```
Step 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Ìò∏Ï∂ú Î∞è ÏΩîÏä§Ìîº ÏßÄÏàò Ï∂îÏ∂ú
Step 2. Í∏∞Ï§Ä Íµ¨Í∞Ñ ÏßÄÏ†ï Î∞è ÏãúÍ∞ÅÌôî
Step 3. Ìå®ÌÑ¥ Í≤ÄÏÉâÍ∏∞ Íµ¨ÌòÑ
Step 4. Í≤ÄÏÉâ Íµ¨Í∞Ñ Ïù¥ÌõÑÏùò Ï∂îÏÑ∏ ÌôïÏù∏
```

**[7. AI, Îî•Îü¨ÎãùÏúºÎ°ú Ï£ºÍ∞ÄÎ•º ÏòàÏ∏°Ìï† Ïàò ÏûàÎã§Í≥†?](https://github.com/sw-song/TIA/blob/main/00_07_price_forecasting/linear_reg.ipynb)**
```
Step 1. ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ÏôÄ ÏòàÏ∏°
Step 2. ÏòàÏ∏° Ïã§Ìóò
Step 3. Í≤∞Í≥º Ìï¥ÏÑù
```

**[8. (ÏΩîÎìú)Bitcoin price forecasting](https://github.com/sw-song/TIA/blob/main/00_08_holt_winters/bitcoin_predict.ipynb)**
- [(ÏÑ§Î™Ö)Îç∞Ïù¥ÌÑ∞Î°ú Î≥¥Îäî ÎπÑÌä∏ÏΩîÏù∏ Í∞ÄÍ≤© Ï†ÑÎßù - Ïù¥ÎèôÌèâÍ∑†Î∂ÄÌÑ∞ ÏßÄÏàòÌèâÌôúÍπåÏßÄ](https://songseungwon.tistory.com/entry/Îç∞Ïù¥ÌÑ∞Î°ú-Î≥¥Îäî-ÎπÑÌä∏ÏΩîÏù∏-Í∞ÄÍ≤©-Ï†ÑÎßù-Ïù¥ÎèôÌèâÍ∑†Î∂ÄÌÑ∞-ÏßÄÏàòÌèâÌôúÍπåÏßÄ)


# TIA(Today I Analyzed) - Kaggle Study
## Description
Ï¢ãÏùÄ Ïª§ÎÑêÏù¥ ÏûàÎã§Î©¥ Îî∞Îùº ÏûëÏÑ±ÌïòÎ©¥ÏÑú Í≥µÎ∂ÄÌï¥Î≥¥Í≥†, ÏßÅÏ†ë Î∂ÑÏÑùÎèÑ ÌïòÍ≥† ÏûàÏäµÎãàÎã§. 
Îî∞Îùº ÏûëÏÑ±Ìïú ÏΩîÎìúÏùò Í≤ΩÏö∞ ÌÉÄÏù¥ÌãÄÏóê +ÌëúÏãúÎ•º Ìï¥ÎíÄÏäµÎãàÎã§.
* **Self** : n. Main Title
* **Clone** : n+. Main Title - Clone Project(Original Title)

---
**[1. HR Analytics : Job Change of Data Scientists - Predict who will move to a new job](https://github.com/sw-song/TIA/blob/main/01_HR_Analytics/HR_Analytics.ipynb)**
```
Step 1. Library Import
Step 2. Data Read
Step 3. EDA
Step 3-1. EDA - Visualization | Numerical Columns
Step 3-2. EDA - Visualization | Categorical Columns
Step 4. Train & Validation Set Î∂ÑÎ¶¨
Step 5. Model ÏÉùÏÑ± Î∞è ÌïôÏäµ
Step 6. Validation data Accuracy Ï∏°Ï†ï
```

**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, HR Analytics for begineer - S P Rakshith)](https://github.com/sw-song/TIA/blob/main/01_HR_Analytics/Clone__HR_Analytics_for_beginners.ipynb)**
```
Step 1. Importing the necessery libraries
Step 2. Importing the Data, head(), info()
Step 3. Checking the total number of Null Data - insa()
Step 4. Visualize the Categorical Data
Step 5. Modeling & Prediction
Step 6. Evaluation - Confusion Matrix
```

**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, Predict who will move to a new job - Siti Khotijah)](https://github.com/sw-song/TIA/blob/main/01_HR_Analytics/Clone__Predict_who_will_move_to_a_new_job.ipynb)**
```
Step 1. Import data
Step 2. Visualization
Step 3. Check missing Value and Replace Them with average of columns
Step 4. Type Tansfer - Categorical to Numerical
Step 5. Modeling & Prediction
Step 6. Evaluation - AUC
```
---

**[2. Youtube trend Analysis : Check Daily statistics for trending Youtube videos](https://github.com/sw-song/TIA/blob/main/02_Youtube_trend_Analysis/youtube_trend_analysis.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Correlation Check - Heatmap
(+Time Series)
Step 3. Visualization - Numerical Columns
Step 4. Visualization - WordCloud
Step 5. Machine Learning Modeling(Keras)
```
---
**[3. NLP with Disaster Tweets - Basic NLP Model, Score : 0.775](https://github.com/sw-song/TIA/blob/main/03_NLP_with_Disaster_Tweets/nlp_disaster_tweets.ipynb)**
```
Step 1. Library Import & Data Load
Step 2. Data Preprocessing
     2-a. Drop Columns
     2-b. Tokenizer
     2-c. Pad Sequences
     2-d. Match Data type to numpy.ndarray
Step 3. Modeling
Step 4. Model Compile
Step 5. Callbacks
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Reload Model
Step 9. Predict Test Data
```

**[3+. NLP with Disaster Tweets - Clone Project(Kaggle, NLP Getting Started Tutorial, Phill Culliton)](https://github.com/sw-song/TIA/blob/main/03_NLP_with_Disaster_Tweets/Clone_NLP_Getting_Started_Tutorial.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Text -> Vectorization(One Hot Encoding)
Step 3. Cross Validation Check
Step 4. Modeling
Step 5. Save / Submission(kaggle)
```

**[3+. NLP with Disaster Tweets - Clone Project(Getting Started with Transfer Learning Using Tensorflow Hub)](https://github.com/sw-song/TIA/blob/main/03_NLP_with_Disaster_Tweets/Clone_TL_using_TFHub.ipynb)**
```
Step 0. Importing Libraries
Step 1. Loading Data
Step 2. Basic EDA
     2-a. Missing Values
     2-b. The Dependent Variable - target
     2-c. Independent Variables
Step 3. Text Preprocessing
     3-a. Text Cleaning
     3-b. Removing Stopwords
     3-c. Lemmatization
Step 4. Wordcloud
Step 5. Modeling Using Pretrained Model
     5-a. Creating Training & Testing Set
Step 6. Prediction
Step 7. Prepare for Submission
```
---

**[4. Telecom Users Dataset Analysis - Predict User's Next Action with Logistic Regression](https://github.com/sw-song/TIA/blob/main/04_Telecom_users_analysis/quick-start-eda-to-machine-learning-logistic.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Data Preprocessing
Step 3. Dataset Split(Train : Test = 0.8 : 0.2)
Step 4. Modeling : Logistic Regression
```

**[4+. Telecom Users Dataset Analysis - Clone Project(Kaggle, EDA and Building models for predicting outflow](https://github.com/sw-song/TIA/blob/main/04_Telecom_users_analysis/Clone_EDA_and_Building_models_for_predicting_outflow.ipynb)**
```
Step 1. Data Description
Step 2. Dependency research and formulation of hypothesis
Step 3. Building models to predict outflow
```
---

**[5. Heart Attack Analysis and Prediction - Binary Classification with Logistic Regression](https://github.com/sw-song/TIA/blob/main/05_Heart_Attack_Analysis_and_Prediction/quick-start-Binary_Classification_with_Logistic_Regression.ipynb)**
```
Step 1. Data Description
Step 2. EDA
Step 3. Correlation Check
Step 4. Test Data Split and Standard Scaling (Test size = 0.3)
Step 5. Modeling and Prediction
```

**[5+. Heart Attack Analysis and Prediction - Clone Project(Kaggle, Heart Attack Prediction_95.4% accuracy)](https://github.com/sw-song/TIA/blob/main/05_Heart_Attack_Analysis_and_Prediction/Clone_Heart_attack_prediction.ipynb)**
```
Step 1. Data Description - missingno
Step 2. EDA - pandas_profiling
Step 3. Data preprocessing - remove Outlier, upsampling
Step 4. modeling / prediction / evaluation
Step 5. check feature importance
```
---

**[6. Bankruptcy Prediction with KNN - Acc 97%](https://github.com/sw-song/TIA/blob/main/06_Company_Bankruptcy_Prediction/Bankruptcy_Prediction_with_KNN.ipynb)**
```
Step 1. Data Description
Step 2. Data Preprocessing - MinMaxScaling
Step 3. Machine Learning Modeling & Prediction
```

**[6+. Bankruptcy_Prediction - Clone Project(Simple, yet, Powerful Bankrupt Prediction Model)](https://github.com/sw-song/TIA/blob/main/06_Company_Bankruptcy_Prediction/Clone_Powerful_Bankrupt_Prediction.ipynb)**
```
Step 1. Data Loading and Data Cleaning
Step 2. Model Based Feature Selection
Step 3. Descriptive Analysis
Step 4. Data Analysis
Step 5. Predicting bankruptcy
Step 6. Conclusions
```
---
**[7. Anomaly Detection with XGB Classifier(base model Accuracy 79%) - Facebook Recruiting IV: Human or Robot?](https://github.com/sw-song/TIA/blob/main/07_Classification_Human_or_Robot/Anomaly_Detection_with_XGBClassifier.ipynb)**
```
Step 1. Data load & EDA
Step 2. Preprocessing - replace all values with count number
Step 3. Preprocessing - Upsampling
Step 4. Train / Valid Set Split
Step 5. Modeling
Step 6. Prediction
```

---
**[8. Stroke Prediction with EASY Ensemble - Acc 90%(Random Forest Base model - 90%, Gradient Boosting Tuning Model)](https://github.com/sw-song/TIA/blob/main/08_Stroke_Prediction/stroke_prediction.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Feature Engineering
     2-a. Binary Features
     2-b. Continuous Features
     2-c. Categorical Features
Step 3. Train / Test set Split & Upsampling
Step 4. Modeling & Prediction
```

**[8+. Stroke Prediction - Clone Project(Stroke Prediction Beginner's Guide)](https://github.com/sw-song/TIA/blob/main/08_Stroke_Prediction/Clone_stroke_prediction.ipynb)**
```
Step 1. Importing the necessary libraries
Step 2. Importing the Data using Pandas read_csv(). And calling head() and info() on the DataFrame
Step 3. Preprocessing Data before Exploratory Data Analysis
Step 4. Exploratory Data Analysis on Stroke Prediction Data
Step 5. Preparing the Data for Prediction
Step 6. Creating a Model for Stroke Prediction
```

---
**[9. Predict Students Performance with MultiOutputRegressor - R2(training set) 45%](https://github.com/sw-song/TIA/blob/main/09_Students_Performance_in_Exams/Predict_Students_Performance.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Visualization
     2-a. Each X's distribution
     2-b. Each y's distribution
     2-c. 'X & y's distribution
Step 3. Data Preprocessing
Step 4. Modeling & Prediction
```

**[9+. Students Performance in Exams - Clone Project(Data Science Notes 4: Machine Learning(ML))](https://github.com/sw-song/TIA/blob/main/09_Students_Performance_in_Exams/Clone_Data_Science_Notes_4.ipynb)**
```
Step 1. Imports and Datasets
Step 2. Regression
     2-a. Linear Regression 
     2-b. Decision Tree Regressor
     2-c. Random Forest Regressor
Step 3. Classification
     3-a. Preparing Data
     3-b. One-Hot Encoding
     3-c. Logistic Regression
     3-d. KNN
     3-e. SVM
     3-f. GaussianNB
     3-g. Decision Tree
     3-h. Random Forest
     3-i. Perceptron
     3-j. Stochastic Gradient Descent (SGD)
     3-k. Ridge Regression
Step 4. Conclusion
```
---
**[10. Breast Cancer Prediction - 3 types(Basic, MinMaxScaled, StandardScaled) of comparison](https://github.com/sw-song/TIA/blob/main/10_Breast_Cancer_Wisconsin/Breast_Cancer_Prediction__with_3type_of_Data.ipynb)**
```
Step 1. Data Load & EDA & Preprocessing
Step 2. Visualization
     2-a. Correlation Heatmap - raw data
     2-b. Correlation Heatmap - MinMaxScaled data
     2-c. Correlation Heatmap - StandardScaled data
Step 3. Modeling & Prediction
     3-a. Logistic Regression - raw data
     3-b. SGDClassifier       - raw data
     3-c. Logistic Regression - MinMaxScaled data
     3-d. SGDClassifier       - MinMaxScaled data
     3-e. Logistic Regression - StandardScaled data
     3-f. SGDClassifier       - StandardScaled data
Step 4. Conclusion
```
 
**[10+. Breast Cancer Prediction - Clone Project(Feature Selection and Data Visualization)](https://github.com/sw-song/TIA/blob/main/10_Breast_Cancer_Wisconsin/Clone_Feature_Selection_and_Data_Visualization.ipynb)**
```
Step 1. Data Analysis
Step 2. Data Visualization
     2-a. violinplot
     2-b. boxplot
     2-c. jointplot
     2-d. pairgrid
     2-e. swarmplot
     2-f. heatmap
Step 3. Feature Selection and Random Forest Classification
     3-a. Feature selection with correlation and random forest classification
     3-b. Univariate feature selection and random forest classification
     3-c. Recursive feature elimination (RFE) with random forest
     3-d. Recursive feature elimination with cross validation (RFECV) and random forest classification
     3-e. Tree based feature selection and random forest classification
Step 4. Feature Extraction
Conclusion
```
---
**[11-(1). Simple NN Basic Model with Fasion MNIST](https://github.com/sw-song/TIA/blob/main/11_Fashion_mnist_classification/fasion_mnist_basic.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load and EDA
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate
```

**[11-(2). Fashion MNIST Classification and Visualization](https://github.com/sw-song/TIA/blob/main/11_Fashion_mnist_classification/fasion_mnist.ipynb)**
```
Step 1. Library Import & Load Dataset
     1-a. Library
     1-b. Datasets
     1-c. Shape of Data
     1-d. Show Image
Step 2. Data Preprocessing
     2-a. class name (y)
     2-b. Normalization (X)
     2-c. Visualization (X)
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Training
Step 6. Model Evaluation
Step 7. Prediction
     7-a. using predict method
     7-b. predict y
     7-c. visualization - Predict Class
     7-d. visualization - Predict target image
```
---
**[12. Simple NN Basic Model with iris dataset](https://github.com/sw-song/TIA/blob/main/12_iris_classification/iris_basic.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate
```
---
**[13. Simple CNN Model with RPS dataset - val_loss : 0.0819](https://github.com/sw-song/TIA/blob/main/13_RPS_Image_Classification/RPS_basic_cnn.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Generator
Step 3. Modeling
Step 4. Model Compile
Step 5. Save Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Reload Model
```
---
**[14-(1). Simple CNN Model with 'Horses or Humans' dataset - val_loss : 0.0181](https://github.com/sw-song/TIA/blob/main/14_Horses_or_Humans/horses_or_humans_classification.ipynb)**
> (High Accuracy, Incorrect assignment of test data)
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Svae
Step 8. Reload Model
```
**[14-(2). Simple CNN Model(&Sigmoid) with 'Horses or Humans' dataset - val_loss : 0.7197](https://github.com/sw-song/TIA/blob/main/14_Horses_or_Humans/horses_or_humans_classification_sigmoid.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Svae
Step 8. Reload Model
```
**[14-(3). Simple CNN Model(&Sigmoid) with 'Horses or Humans' dataset (+callbacks, learning rate scheduler) - val_loss : 0.6627](https://github.com/sw-song/TIA/blob/main/14_Horses_or_Humans/horses_or_humans_classification_callbacks.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Svae
Step 8. Reload Model
```
---
**[15-(1). Simple CNN Model with 'Cats vs Dogs' dataset - val_loss : 0.3119](https://github.com/sw-song/TIA/blob/main/15_Cats_vs_Dogs/cnn_3119/cats_vs_dogs_classification.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Svae
Step 8. Reload Model
```
**[15-(2). VGG16 Transfer CNN Model with 'Cats vs Dogs' dataset - val_loss : 0.1579](https://github.com/sw-song/TIA/blob/main/15_Cats_vs_Dogs/vgg16_1579/cats_vs_dogs_classification_with_vgg16.ipynb)**
```
Step 0. Library Import
Step 1. Load Dataset
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Model Reload
```
---
**[16. Simple NLP Model with 'sarcasm' dataset - val_loss : 0.3687](https://github.com/sw-song/TIA/blob/main/16_sarcasm/sarcasm.ipynb)**
```
Step 0. Library Import
Step 1. Load Dataset
Step 2. Data Preprocessing
     2-a. Train/Test split
     2-b. Tokenizer
     2-c. Pad Sequences
     2-d. label type : list -> numpy array
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Reload Model
```
**[16+. Sarcasm in News Headlines Classification - Clone Project(Sarcasm Detection : A Guide for ML and DL approach)](https://github.com/sw-song/TIA/blob/main/16_sarcasm/Clone_sarcasm.ipynb)**
```
Step 1. Loading and Viewing the Sample Dataset
Step 2. ML Approach
Step 3. DL Approach

```
---
**[17. Time Series Forcasting Model based on LSTM with 'sunspots' dataset - val_mae : 13.90](https://github.com/sw-song/TIA/blob/main/17_sunspots/timeseries_sunspots.ipynb)**
```
Step 0. Library Import
Step 1. Load Dataset
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Model Reload
```

**[17+. Time Series Forcasting Model based on LSTM with 'sunspots' dataset - Clone Project(Time Series - TensorFlow RNN-LSTM Introduction)](https://github.com/sw-song/TIA/blob/main/17_sunspots/Clone_timeseries_sunspots.ipynb)**
```
Step 0. Library Import
Step 1. Load Dataset
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Callbacks
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Model Reload
```
---
**[18-(1). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | Step-by-Step Tutorial From EDA To Preprocessing for Image Detection](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/step-by-step-tutorial-from-eda-to-preprocessing.ipynb)**
```
Step 1. Import Libraries
Step 2. Load Data
Step 3. Read DCM File
     3-a. explore path with python code
     3-b. make image extractor(function)
Step 4. Show Sample Image
     4-a. explore image data with python code
     4-b. check position to draw box
Step 5. Show Multiple Images
Step 6. Feature Engineering
     6-a. count opacity
     6-b. simplify 'id'
     6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'
     6-d. check the relation between 'OpacityCount' and other columes in train_study
     6-e. visualize the relation between 'OpacityCount' and other columes in train_study
     6-f. check duplicate values(One row and Two Appearances)
```  

**[18-(2). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM Step by Step Image Detection for Beginners](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-step-by-step-image-detection-for-beginners.ipynb)**
```
Step 1. Import Libraries
Step 2. Load Data
Step 3. Read DCM File
     3-a. explore path with python code
     3-b. make image extractor(function)
Step 4. Show Sample Image
     4-a. explore image data with python code
     4-b. check position to draw box
Step 5. Show Multiple Images
Step 6. Feature Engineering I
     6-a. count opacity
     6-b. simplify 'id'
     6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'
     6-d. check the relation between 'OpacityCount' and other columes in train_study
     6-e. visualize the relation between 'OpacityCount' and other columes in train_study
     6-f. check duplicate values(One row and Two Appearances)
Step 7. Feature Engineering II
     7-a. explore data analysis
     7-b. check duplicates in dataset
     7-c. modify some of the code in function that extract image(.dcm)
Step 8. Visualize X-ray with bbox
     8-a. negative for pneumonia
     8-b. typical appearance
     8-c. indeterminate appearance
     8-d. atypical Appearance
Step 9. Featrue Engineering III
     9 .. ing
```  

**[18-(3). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM-COVID-19 Detection - 10 Step Tutorial](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-covid-19-detection-10-step-tutorial.ipynb)**
```
Step 1. Import Libraries
Step 2. Load Data
Step 3. Read DCM File
     3-a. explore path with python code
     3-b. make image extractor(function)
Step 4. Show Sample Image
     4-a. explore image data with python code
     4-b. check position to draw box
Step 5. Show Multiple Images
Step 6. Feature Engineering I
     6-a. count opacity
     6-b. simplify 'id'
     6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'
     6-d. check the relation between 'OpacityCount' and other columes in train_study
     6-e. visualize the relation between 'OpacityCount' and other columes in train_study
     6-f. check duplicate values(One row and Two Appearances)
Step 7. Feature Engineering II
     7-a. explore data analysis
     7-b. check duplicates in dataset
     7-c. modify some of the code in function that extract image(.dcm)
Step 8. Visualize X-ray with bbox
     8-a. negative for pneumonia
     8-b. typical appearance
     8-c. indeterminate appearance
     8-d. atypical Appearance
Step 9. Featrue Engineering III
     9-a. anomaly detection
     9-b. show outliers in `Typical Appearance`
     9-c. show outliers in `Intermiate Appearance`
     9-d. show outliers in `Atypical Appearance`
Step 10. Image Data Preprocessing
```  

**[18-(4). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM: COVID-19 Detection üî± 10+Step Tutorial (1)](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-covid-19-detection-10-step-tutorial-1.ipynb)**
```
Step 1. Import Libraries
Step 2. Load Data
Step 3. Read DCM File
     3-a. explore path with python code
     3-b. make image extractor(function)
Step 4. Show Sample Image
     4-a. explore image data with python code
     4-b. check position to draw box
Step 5. Show Multiple Images
Step 6. Feature Engineering I
     6-a. count opacity
     6-b. simplify 'id'
     6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'
     6-d. check the relation between 'OpacityCount' and other columes in train_study
     6-e. visualize the relation between 'OpacityCount' and other columes in train_study
     6-f. check duplicate values(One row and Two Appearances)
Step 7. Feature Engineering II
     7-a. explore data analysis
     7-b. check duplicates in dataset
     7-c. modify some of the code in function that extract image(.dcm)
Step 8. Visualize X-ray with bbox
     8-a. negative for pneumonia
     8-b. typical appearance
     8-c. indeterminate appearance
     8-d. atypical Appearance
Step 9. Featrue Engineering III
     9-a. anomaly detection
     9-b. show outliers in `Typical Appearance`
     9-c. show outliers in `Intermiate Appearance`
     9-d. show outliers in `Atypical Appearance`
Step 10. Image Data Preprocessing
     10-a. add image path to a separate column
     10-b. Resize the image (uniform to 150x150) and Scale each pixel values (uniform range 1~255)
     10-c. Calculate the resize ratio(x, y) and Apply the same to the bounding box
```  

**[18-(5). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM: COVID-19 Detection üî± 10+Step Tutorial (2)](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-covid-19-detection-10-step-tutorial-2.ipynb)**
```
Step 1. Load Data and Trim for use
     1-a. load train-dataframe
     1-b. load meta-dataframe
     1-c. load image data array
     1-d. calculate image resize ratio information
Step 2. Image Pre-Classification with Data generator
     2-a. classify image id by opacity types
     2-b. sort image files into each type's folder
     2-c. data generation, split train/valid set
Step 3. Modeling - Multiclass classifier
     3-a. import libraries
     3-b. basic modeling with keras api
     3-c. model compile
     3-d. save model checkpoint
     3-e. model fit
     3-f. model evaluate & save
     3-g. reload model & model summary
```

**[18-(6). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM: COVID-19 Detection üî± 10+Step Tutorial (2)](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-covid-19-detection-10-step-tutorial-2-2.ipynb)**
```
Step 1. Load Data and Trim for use
     1-a. load train-dataframe
     1-b. load meta-dataframe
     1-c. load image data array
     1-d. calculate image resize ratio information
Step 2. Image Pre-Classification with Data generator
     2-a. classify image id by opacity types
     2-b. sort image files into each type's folder
     2-c. data generation, split train/valid set
Step 3. Modeling I - Basic Multiclass classifier
     3-a. import libraries
     3-b. basic modeling with keras api
     3-c. model compile
     3-d. save model checkpoint
     3-e. model fit
     3-f. model evaluate & save
     3-g. reload model & model summary
Step 4. Modeling II - Multiclass classifier using EfficientNet(Transfer Learning)
     4-a. Load the EfficientNet and try it out
     4-b.  Improving performance with an appropriate form
```


**[18-(7). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | Tutorial : Multi-Output Regression](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/multi_output_regression_tutorial.ipynb)**
```
Step 1. Get the dataset
Step 2. Get the model
Step 3. Evaluate a model using repeated k-fold cross-validation
Step 4. Load dataset
Step 5. Evaluate model
Step 6. Practical Application
```

**[18-(8). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM: COVID-19 Detection üî± Mini Part - Preprocess](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-covid-19-detection-mini-part-preprocess.ipynb)**
```
Step 1. Import Dataset
Step 2. Test Sample data(1 row) before make the preprocessing function
     2-a. The image with the most opacity detected is taken as a sample
     2-b. visualize resized image without boxes
     2-c. extract position information
     2-d. Extract all box's information for sample image.
     2-e. Extract corrected positions that resizing ratio is calculated
     2-f. visualize resized image with boxes
Step 3. Build Function for reuse
     3-a. Test the functions that go into the function
     3-b. Build Function and Create New DataFrame with loop
     3-c. concat dataframe and save
```

**[18-(9). Archive For Kaggle Competition | SIIM-FISABIO-RSNA COVID-19 Detection | SIIM: COVID-19 Detection üî± MultiOutput Regression](https://github.com/sw-song/TIA/blob/main/18_SIIM-FISABIO-RSNA_COVID-19_Detection/siim-covid-19-detection-multioutput-regression.ipynb)**
```
Step 1. Load Train Data Table
     1-a. extract data with only one opacity
     1-b. extract image paths
Step 2. Load Image Dataset
     2-a. Data Preprocessing
Step 3. Modeling
     3-a. Train-valid split
     3-b. Modeling
     3-c. Training
     3-d. Evaluation
 ```

---
 **[19+. Conditional GAN Basic with PyTorch - Clone Project(Conditional Generative Adversarial Network)](https://github.com/sw-song/TIA/blob/main/19_Conditional_GAN_Basic/clone-conditional-generative-adversarial-network.ipynb)**
```
Step 1. Load Data
     1-a. read csv
     1-b. x & y split
     1-c. data preprocessing - x
     1-d. data preprocessing - y 
     1-e. show sample image
Step 2. Modeling
     2-a. generator network
     2-b. discriminator network
     3-c. instantiate the networks
     3-d. moving the networks to the gpu
     3-e. create the loss function and optimizers
     3-f. creating network optimizing functions 
Step 3. Model Training
```

**[19-(1). Generate Fashion images with Conditional GAN ..ing](https://github.com/sw-song/TIA/blob/main/19_Conditional_GAN_Basic/generate-fashion-images-with-conditional-gan.ipynb)**
```
Step 1. Import Libraries and Load Dataset
     1-a. basic way to load dataset
     1-b. more efficient way to load dataset(with transform) + batch
Step 2. Define Discriminator and Generator
     2-a. discriminator
     2-b. generator
Step 3. Define Loss Function and Optimizing Function
     3-a. loss function
     3-b. optimizing function
Step 4. Define Training Functions
     4-a. training gerenator (get 1 loss and 1 gradient descent)
     4-b. training discriminator (get 1 loss and 1 gradient descent)
Step 5. Train Model
```

**[19-(2). Generate Fashion images with Conditional GAN - final](https://github.com/sw-song/TIA/blob/main/19_Conditional_GAN_Basic/generate-fashion-images-with-conditional-gan-final.ipynb)**
```
Step 1. Import Libraries and Load Dataset
     1-a. basic way to load dataset
     1-b. more efficient way to load dataset(with transform) + batch
Step 2. Define Discriminator and Generator
     2-a. discriminator
     2-b. generator
Step 3. Define Loss Function and Optimizing Function
     3-a. loss function
     3-b. optimizing function
Step 4. Define Training Functions
     4-a. training gerenator (get 1 loss and 1 gradient descent)
     4-b. training discriminator (get 1 loss and 1 gradient descent)
Step 5. Train Model
Step 6. Test Model
```
---
**[20+. Animal Face Classification with PyTorch - Clone Project(Pytorch Animal Face Classification - CNN)](https://github.com/sw-song/TIA/blob/main/20_PyTorch_Classification_Basic/clone-pytorch-animal-face-classification.ipynb)**
```
Step 1. Preparing Dataset
     1-a. Preparing Dataset Class
     1-b. Preparing Sampler Objects
     1-c. Preparing Data Loader Objects
Step 2. Neural Network Modeling
Step 3. Training Model
Step 4. Final Test
Step 5. Save a PyTorch Model
```

---
**[21. PyTorch Basic to CNN - Clone Project(Pytorch Tutorial for Deep Learning Lovers)](https://github.com/sw-song/TIA/blob/main/21_Pytorch_Neural_Net/clone-pytorch-tutorial-for-deep-learning-lovers.ipynb)**
```
Step 1. Basics of pytorch
Step 2. Linear regression with pytorch
Step 3. Logistic regression with pytorch
Step 4. Artificial neural network with pytorch
Step 5. Convolutional neural network with pytorch
```

---
**[22. GAN Basic Tutorial : Generate MNIST](https://github.com/sw-song/TIA/blob/main/22_PyTorch_GAN_MNIST/overview-of-basic-gan-architecture.ipynb)**
```
Step 1. Import Libraries
Step 2. Initial Setting
Step 3. Define Generator
Step 4. Define Discriminator
Step 5. Define Loss Function
Step 6. Initialize Generator and Discriminator
Step 7. GPU Setting
Step 8. Configure Data Loader
Step 9. Define Optimizers
Step 10. Training
```
---
**[23-(1). (blueprint)CycleGAN Tutorial : Monet to Photo](https://github.com/sw-song/TIA/blob/main/23_PyTorch_CycleGAN_Monet_to_Photo/cyclegan_tutorial_monet_to_photo.ipynb)**
```
Step 1. Import Libraries
Step 2. Initial Setting
Step 3. Define Generator
Step 4. Define Discriminator
Step 5. Define Loss Function
Step 6. Initialize Generator and Discriminator
Step 7. GPU Setting
Step 8. Weight Setting
Step 9. Configure Optimizer
Step 10. Learning Rate Scheduler Setting
Step 11. Image Transformation Setting
Step 12. DataLoader Setting
Step 13. Define function to get sample images
Step 14. Training
```

**[23-(2). (final)CycleGAN Tutorial : Monet to Photo](https://github.com/sw-song/TIA/blob/main/23_PyTorch_CycleGAN_Monet_to_Photo/final_cyclegan-tutorial-monet-to-photo.ipynb)**
```
Step 1. Import Libraries
Step 2. Initial Setting
Step 3. Define Generator
Step 4. Define Discriminator
Step 5. Define Loss Function
Step 6. Initialize Generator and Discriminator
Step 7. GPU Setting
Step 8. Weight Setting
Step 9. Configure Optimizer
Step 10. Learning Rate Scheduler Setting
Step 11. Image Transformation Setting
Step 12. DataLoader Setting
Step 13. Define function to get sample images
Step 14. Training
```
---

**[24-(1). (blueprint)StarGAN Tutorial : Generate Celeb Images](https://github.com/sw-song/TIA/blob/main/24_PyTorch_StarGAN_CelebA/stargan-tutorial-generate-celeb-images.ipynb)**
```
Step 1. Import Libraries
Step 2. Initial Setting
Step 3. Define Generator
Step 4. Define Discriminator
Step 5. Define Loss function and Initialize Loss weights
Step 6. Initialize Generator and Discriminator
Step 7. GPU Setting
Step 8. Weight Setting
Step 9. Configure Optimizers
Step 10. Set transforms and Configure DataLoaders
Step 11. Define Gradient Penalty Function
Step 12. Define function to get sample images with input label list
Step 13. Training
```

**[24-(2). (final)StarGAN Tutorial : Generate Celeb Images](https://github.com/sw-song/TIA/blob/main/24_PyTorch_StarGAN_CelebA/final_stargan-tutorial-generate-celeb-images.ipynb)**
```
Step 1. Import Libraries
Step 2. Initial Setting
Step 3. Define Generator
Step 4. Define Discriminator
Step 5. Define Loss function and Initialize Loss weights
Step 6. Initialize Generator and Discriminator
Step 7. GPU Setting
Step 8. Weight Setting
Step 9. Configure Optimizers
Step 10. Define CelebADataset Class for handling labeled dataset
Step 11. Set transforms and Configure Dataloader for training
Step 12. Set transforms and Configure Dataloader for testing
Step 13. Define Gradient Penalty Function
Step 14. Define function to get sample images with input label list
Step 15. Training
```
---

**[25. Image Generation using Stylegan pre-trained model](https://github.com/sw-song/TIA/blob/main/25_PyTorch_Stylegan_Using_Pre-trained-model/image-generation-using-stylegan-pre-trained-model.ipynb)**
```
Step 1. Import Libraries
Step 2. Design Layers
     2-a. linear layer
     2-b. convolution layer
     2-c. noise layer
     2-d. style modification layer
     2-e. pixel normalization layer
     2-f. blur layer
     2-g. upscaling layer
Step 3. Design Networks
     3-a. generator mapping network
     3-b. generator synthesis blocks
     3-c. generator synthesis network
Step 4. Define the Model (Image Generator)
     4-a. data flow : z to image
     4-b. load pre-trained weight
Step 5. Test the Model
     5-a. gpu setting
     5-b. input setting - grid
     5-c. input setting - latent z
     5-d. show samples
Step 6. Control Latent Vector
     6-a. first random latent vector + generate first image
     6-b. second random latent vector + generate second image
     6-c. half `z` + half `z`
     6-d. half `w` + half `w`
     6-e. Image Interpolation Comparison
```
---

**[26-(1). (Step ~2)Image Generation using Stylegan pre-trained model](https://github.com/sw-song/TIA/blob/main/26_Generate_Dog_with_StyleGAN2-ada/step1~2_stylegan2-ada.ipynb)**
```
Step 1. Initial Setting and load pre-trained model
     1-a. import libraries
     1-b. clone the stylegan2-ada's git repository
     1-c. load pre-trained model that trained on afhqdog dataset
Step 2. generate sample fake-dog images
     2-a. a quick look at the model
     2-b. try submodels : g_mapping, g_synthesis
```


**[26-(2). (Step ~3)Image Generation using Stylegan pre-trained model](https://github.com/sw-song/TIA/blob/main/26_Generate_Dog_with_StyleGAN2-ada/step+3_stylegan2-ada.ipynb)**
```
Step 1. Initial Setting and load pre-trained model
     1-a. import libraries
     1-b. clone the stylegan2-ada's git repository
     1-c. load pre-trained model that trained on afhqdog dataset
Step 2. generate sample fake-dog images
     2-a. a quick look at the model
     2-b. try submodels : g_mapping, g_synthesis
Step 3. image morphing
     3-a. create 2 random vector z and 2 intermediate latent space w
     3-b. generate 2 target fake-dog images
     3-c. control `z` and try image interpolation
```

**[26-(3). (Step ~4)Image Generation using Stylegan pre-trained model](https://github.com/sw-song/TIA/blob/main/26_Generate_Dog_with_StyleGAN2-ada/step+4_stylegan2-ada.ipynb)**
```
Step 1. Initial Setting and load pre-trained model
     1-a. import libraries
     1-b. clone the stylegan2-ada's git repository
     1-c. load pre-trained model that trained on afhqdog dataset
Step 2. generate sample fake-dog images
     2-a. a quick look at the model
     2-b. try submodels : g_mapping, g_synthesis
Step 3. image morphing
     3-a. create 2 random vector z and 2 intermediate latent space w
     3-b. generate 2 target fake-dog images
     3-c. control `z` and try image interpolation
Step 4. Project sample image to the latent space of pretrained network
     4-a. load a target image
     4-b. transform image file to numpy array
     4-c. load the pre-trained Generator
     4-d. Compute w stats
     4-e. Setup noise inputs
     4-f. Load VGG16 feature detector
     4-g. Extract features for target image
     4-h. Set optimizer and Initiate noise
     4-i. projection(training)
     4-j. Compare the target image with the generated image
Step 5. Change the characteristics of a new image
```

**[26-(4). StyleGAN2-ADA : Style Conversion - Changing A Dog's Facial Expression (master version of Image Generation using Stylegan pre-trained model)](https://github.com/sw-song/TIA/blob/main/26_Generate_Dog_with_StyleGAN2-ada/stylegan2-ada-change-a-dog-s-facial-expression.ipynb)**
```
Step 1. Initial Setting and load pre-trained model
     1-a. import libraries
     1-b. clone the stylegan2-ada's git repository
     1-c. load pre-trained model that trained on afhqdog dataset
Step 2. generate sample fake-dog images
     2-a. a quick look at the model
     2-b. try submodels : g_mapping, g_synthesis
Step 3. image morphing
     3-a. create 2 random vector z and 2 intermediate latent space w
     3-b. generate 2 target fake-dog images
     3-c. control `z` and try image interpolation
Step 4. Project sample image to the latent space of pretrained network
     4-a. load a target image
     4-b. transform image file to numpy array
     4-c. load the pre-trained Generator
     4-d. Compute w stats
     4-e. Setup noise inputs
     4-f. Load VGG16 feature detector
     4-g. Extract features for target image
     4-h. Set optimizer and Initiate noise
     4-i. projection(training)
     4-j. Compare the target image with the generated image
Step 5. Style Conversion
     5-a. Extract information about smiling expressions
     5-b. Import w to insert facial expressions
```

**[27+. Clone Project(bitcoin eda and forecasting using pycaret)](https://github.com/sw-song/TIA/blob/main/27_Crypto_Forecasting/clone-bitcoin-eda-and-forecasting-using-pycaret.ipynb)**
```
1. Importing dataset
2. Filtering bitcoin from dataset
   2-1. checking for null values
   2-2. dropping null values
   2-3. changing unix timestamp into date and time
3. Explanatory data analysis
   3-1. statistics of bitcoin
   3-2. some insights about bitcoin
   3-3. vwap as per time
   3-4. trading volume as per time
   3-5. the number of trades that took place as per time
   3-6. correlation
4. Using pycaret for forcasting close price of bitcoin
   4-1. installing pycaret
   4-2. setting up the model and comparing between different models
   4-3. plotting the best model
```

**[27+. Clone Project(Crypto Forecasting Tutorial) + translate](https://github.com/sw-song/TIA/blob/main/27_Crypto_Forecasting/crypto-forecasting-tutorial.ipynb)**
```
1. G-Research Crypto forecasting competition
   1-1. The Cryptocurrency Market(ÏïîÌò∏ÌôîÌèê ÏãúÏû•)
   1-2. Forecasting returns(ÏàòÏùµ ÏòàÏ∏°)
2. Dataset description(Îç∞Ïù¥ÌÑ∞ÏÖã ÏÜåÍ∞ú)
   2-1. Load the training set(ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞)
   2-2. Data features
   2-3. Candlestick charts(Ï∫îÎì§ Ï∞®Ìä∏)
3. Preprocessing(Ï†ÑÏ≤òÎ¶¨)
   3-1. Dealing with missing data(Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨)
   3-2. Data visualization
   3-3. Log returns(Î°úÍ∑∏ Î≥ÄÌôòÎêú ÏàòÏùµ)
   3-4. Correlation between assets
4. Building your prediction model(ÏòàÏ∏° Î™®Îç∏ Íµ¨ÌòÑ)
   4-1. Prediction targets and evaluation
   4-2. Feature design
   4-3. Preparing the data for building predictive models
   4-4. Baseline model: Linear Regression(ÏÑ†Ìòï ÌöåÍ∑Ä)
```
